---
title: "New Feature Template"
subtitle: "Run ID: `r params$added_variable`"
date: "`r Sys.Date()`"
author: "Cook County Assessor's Office Data Department"
execute:
  echo: false
  warning: false
  asis: true
format:
  html:
    embed-resources: true
    toc: true
    toc_float: true
    fig-align: center
    fontsize: 12pt
params:
  run_id: "2024-07-03-charming-boni"
  run_id_year: "2024"
  comparison_run_id: "2024-03-17-stupefied-maya"
  comparison_run_id_year: "2024"
  added_variable: "prox_nearest_new_construction_dist_ft"
  added_variable_shap: "prox_nearest_new_construction_dist_ft_shap"
  min_range: 5
  max_range: 95
  type: "continuous"
---

```{r packages}
library(purrr)
library(here)
library(yaml)
# Load list of helper files and main libraries
purrr::walk(list.files(here::here("R"), "\\.R$", full.names = TRUE), source)

# Load reporting-only R libraries
suppressPackageStartupMessages({
  reporting_libs <- "Config/renv/profiles/reporting/dependencies"
  purrr::walk(
    strsplit(read_yaml(here::here("DESCRIPTION"))[[reporting_libs]], ", ")[[1]],
    library,
    character.only = TRUE
  )
})

# TODO: Catch for weird Arrow bug with SIGPIPE. Need to permanently fix later
# https://github.com/apache/arrow/issues/32026
cpp11::cpp_source(code = "
#include <csignal>
#include <cpp11.hpp>

[[cpp11::register]] void ignore_sigpipes() {
  signal(SIGPIPE, SIG_IGN);
}
")

ignore_sigpipes()

# Initialize a dictionary of file paths. See misc/file_dict.csv for details
paths <- model_file_dict(model_params$run_id, model_params$year)
```

```{r download_new_data}
analyses_paths <- list(
  output = list(
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/performance/year=", params$run_id_year, "/stage=assessment/", params$run_id, ".parquet"),
      key = "performance"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/metadata/year=", params$run_id_year, "/", params$run_id, ".parquet"),
      key = "metadata"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/shap/year=", params$run_id_year, "/run_id=", params$run_id, "/"),
      key = "shap"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/assessment_card/year=", params$run_id_year, "/run_id=", params$run_id, "/"),
      key = "assessment_card"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/assessment_pin/year=", params$run_id_year, "/run_id=", params$run_id, "/"),
      key = "assessment_pin"
    )
  )
)

fetch_analyses <- function(run_id, year, analyses_paths) {
  tictoc::tic(paste0("Fetched run: ", run_id))

  s3_objs <- grep("s3://", unlist(analyses_paths$output), value = TRUE)
  bucket <- strsplit(s3_objs[1], "/")[[1]][3]

  data_list <- list()

  for (analyses_path in analyses_paths$output) {
    is_directory <- endsWith(analyses_path$s3, "/")
    if (is_directory) {
      partitioned_by_run <- endsWith(analyses_path$s3, paste0("run_id=", run_id, "/"))
      if (partitioned_by_run) {
        dir_path <- analyses_path$s3
      } else {
        dir_path <- paste0(analyses_path$s3, "year=", year, "/run_id=", run_id, "/")
      }

      message("Now fetching: ", dir_path)
      objs_prefix <- sub(paste0("s3://", bucket, "/"), "", dir_path)
      objs <- aws.s3::get_bucket_df(bucket, objs_prefix)
      objs <- dplyr::filter(objs, Size > 0)

      if (nrow(objs) > 0) {
        combined_data <- NULL
        for (key in objs$Key) {
          message("Now fetching: ", key)
          local_temp_path <- file.path(tempdir(), basename(key))
          aws.s3::save_object(key, bucket = bucket, file = local_temp_path)

          # Read the Parquet file and append it to combined_data
          temp_data <- arrow::read_parquet(local_temp_path)
          if (is.null(combined_data)) {
            combined_data <- temp_data
          } else {
            combined_data <- dplyr::bind_rows(combined_data, temp_data)
          }
        }
        data_list[[analyses_path$key]] <- combined_data
      } else {
        warning(analyses_path$key, " does not exist for this run")
      }
    } else {
      message("Now fetching: ", analyses_path$s3)
      if (aws.s3::object_exists(analyses_path$s3, bucket = bucket)) {
        local_temp_path <- file.path(tempdir(), basename(analyses_path$s3))
        aws.s3::save_object(analyses_path$s3, bucket = bucket, file = local_temp_path)
        data_list[[analyses_path$key]] <- arrow::read_parquet(local_temp_path)
      } else {
        warning(analyses_path$key, " does not exist for this run")
      }
    }
  }

  tictoc::toc()
  return(data_list)
}

data <- fetch_analyses(params$run_id, params$run_id_year, analyses_paths)

performance <- data$performance
metadata <- data$metadata
shap <- data$shap
assessment_card <- data$assessment_card %>%
  select(meta_pin, meta_card_num, pred_card_initial_fmv)

assessment_pin <- data$assessment_pin

lockfile <- metadata$dvc_md5_assessment_data

s3_path <- paste0(
  "s3://ccao-data-dvc-us-east-1/files/md5/",
  substr(lockfile, 1, 2), "/",
  substr(lockfile, 3, nchar(lockfile))
)

# Read the Parquet file directly from S3
assessment_data <- s3read_using(FUN = read_parquet, object = s3_path)
```

```{r download_comparison_data}
analyses_paths <- list(
  output = list(
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/performance/year=", params$comparison_run_id_year, "/stage=assessment/", params$comparison_run_id, ".parquet"),
      key = "performance"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/assessment_pin/year=", params$comparison_run_id_year, "/run_id=", params$comparison_run_id, "/"),
      key = "assessment_pin"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/shap/year=", params$comparison_run_id_year, "/run_id=", params$comparison_run_id_year, "/"),
      key = "shap"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/metadata/year=", params$comparison_run_id_year, "/", params$comparison_run_id, ".parquet"),
      key = "metadata"
    )
  )
)

data_comparison <- fetch_analyses(params$comparison_run_id, params$comparison_run_id_year, analyses_paths)

metadata_comparison <- data_comparison$metadata
model_performance_assessment_comparison <- data_comparison$performance
shap_comparison <- data_comparison$shap

assessment_pin_comparison <- data_comparison$assessment_pin %>%
  select(meta_pin, pred_pin_final_fmv, sale_ratio_study_price, meta_nbhd_code, meta_triad_code, pred_pin_initial_fmv, meta_township_code)
```

```{r data_processing}
assessment_data_small <- assessment_data %>%
  select(meta_pin, meta_card_num, meta_nbhd_code, loc_longitude, loc_latitude, !!sym(params$added_variable))

# Process the working data
working_data <- shap %>%
  select(meta_pin, meta_card_num, pred_card_shap_baseline_fmv, !!sym(params$added_variable)) %>%
  rename(!!params$added_variable_shap := !!sym(params$added_variable)) %>%
  inner_join(assessment_data_small, by = c("meta_pin", "meta_card_num")) %>%
  inner_join(assessment_card, by = c("meta_pin", "meta_card_num")) %>%
  group_by(meta_nbhd_code) %>%
  mutate(
    !!paste0(params$added_variable, "_shap_neighborhood_mean") := mean(abs(!!sym(params$added_variable_shap)), na.rm = TRUE),
    !!paste0(params$added_variable, "_shap_neighborhood_90th") := quantile(abs(!!sym(params$added_variable_shap)), 0.9, na.rm = TRUE),
    !!paste0(params$added_variable, "_neighborhood_mean") := mean(!!sym(params$added_variable), na.rm = TRUE),
    !!paste0(params$added_variable, "_neighborhood_median") := median(!!sym(params$added_variable), na.rm = TRUE),
    !!paste0(params$added_variable, "_neighborhood_90th") := quantile(!!sym(params$added_variable), 0.9, na.rm = TRUE),
    mean_value = mean(abs(!!sym(paste0(params$added_variable_shap))), na.rm = TRUE),
    median_card_value = median(pred_card_initial_fmv, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  inner_join(assessment_pin %>% select(meta_pin, pred_pin_final_fmv), by = "meta_pin") %>%
  rename(pred_pin_final_fmv_new = pred_pin_final_fmv) %>%
  inner_join(assessment_pin_comparison %>% select(meta_pin, pred_pin_final_fmv), by = "meta_pin") %>%
  rename(pred_pin_final_fmv_comparison = pred_pin_final_fmv) %>%
  mutate(
    diff_pred_pin_final_fmv = pred_pin_final_fmv_new - pred_pin_final_fmv_comparison,
    pred_pin_final_fmv_new = scales::dollar(pred_pin_final_fmv_new),
    pred_pin_final_fmv_comparison = scales::dollar(pred_pin_final_fmv_comparison)
  )

nbhd <- ccao::nbhd_shp

spatial_data <- working_data %>%
  distinct(meta_nbhd_code, .keep_all = TRUE) %>%
  inner_join(nbhd, by = c("meta_nbhd_code" = "town_nbhd")) %>%
  st_as_sf()
```

# Descriptive Statistics

```{r mean_median}
descriptives <- working_data %>%
  summarize(
    mean = mean(!!sym(params$added_variable), na.rm = TRUE),
    median = median(!!sym(params$added_variable), na.rm = TRUE)
  )

kable(descriptives)
```

## Histogram

```{r histogram}
ggplot(working_data, aes(x = !!sym(params$added_variable))) +
  geom_histogram(binwidth = 1, fill = "black", color = "black", alpha = 0.7) +
  geom_vline(aes(xintercept = mean(!!sym(params$added_variable), na.rm = TRUE)),
    color = "red", linetype = "dashed", linewidth = 1, show.legend = TRUE
  ) +
  geom_vline(aes(xintercept = median(!!sym(params$added_variable), na.rm = TRUE)),
    color = "green", linetype = "dashed", linewidth = 1, show.legend = TRUE
  ) +
  labs(
    title = paste("Histogram of", params$added_variable),
    x = params$added_variable,
    y = "Frequency"
  ) +
  theme_minimal() +
  annotate("text", x = mean(descriptives$mean), y = Inf, label = "Mean", color = "red", vjust = 1.5, hjust = -3) +
  annotate("text", x = mean(descriptives$median), y = Inf, label = "Median", color = "green", vjust = 1.5, hjust = -1)
```

## Correlation between Added Variable and Other Variables

While tree-based models are not particularly sensitive to multicollinearity, but it is still important to understand the relationship between the new variable and the existing variables. In this table, we should be looking to see if we can identify another variable which *very* neatly aligns with other existing variables. Columns are produced with both the absolute value of the correlation (for easy sorting), as well as the correlation to help decipher the direction of the relationship.

```{r correlation between variables}
columns_to_remove <- c(
  "time_sale_year",
  "time_sale_month_of_year",
  "time_sale_day_of_year",
  "time_sale_day_of_week",
  "time_sale_day_of_month",
  "time_sale_day"
)

if (params$type == "continuous") {
  # Select only numeric columns from assessment_data and remove the specified columns
  numeric_cols <- assessment_data %>%
    select_if(is.numeric) %>%
    select(-all_of(columns_to_remove))

  # Initialize a data frame to store correlation results
  correlation_results <- data.frame(Column = character(), Correlation = numeric(), Abs_Correlation = numeric(), stringsAsFactors = FALSE)

  # Loop through each numeric column and calculate correlation and absolute correlation
  for (col_name in names(numeric_cols)) {
    # Filter out rows with missing values in the two columns being compared
    complete_cases <- complete.cases(numeric_cols[[col_name]], assessment_data[[params$added_variable]])

    # Only compute correlation if there are complete cases
    if (sum(complete_cases) > 0) {
      correlation_value <- cor(numeric_cols[[col_name]][complete_cases], assessment_data[[params$added_variable]][complete_cases], use = "complete.obs")
      abs_correlation_value <- abs(cor(abs(numeric_cols[[col_name]][complete_cases]), abs(assessment_data[[params$added_variable]][complete_cases]), use = "complete.obs"))
      correlation_results <- rbind(correlation_results, data.frame(Column = col_name, Correlation = correlation_value, Abs_Correlation = abs_correlation_value))
    }
  }

  # Sort the correlation results in descending order by Correlation
  correlation_results <- correlation_results %>%
    arrange(dplyr::desc(Abs_Correlation)) %>%
    mutate(across(where(is.numeric), ~ round(., 2)))

  # Display the correlation results as a scrollable table
  datatable(correlation_results, options = list(scrollX = TRUE, scrollY = TRUE, pageLength = 10, order = list(list(1, "desc"))))
} else {
  print(paste("assessment_data$", params$added_variable, " is not numeric.", sep = ""))
}
```

# Overview of Model Metrics

```{r model_stats}
# Function to calculate the percentage difference
percentage_diff <- function(x, y) {
  scales::percent((y - x) / x)
}


min_n <- 10

gte_n <- \(n_sales, min_n, fn, na_type) {
  ifelse(sum(!is.na(n_sales)) >= min_n, fn, na_type)
}
rs_fns_list <- list(
  cod_no_sop = \(x, y) gte_n(y, 2, cod(x / y, na.rm = TRUE), NA_real_),
  prd_no_sop = \(x, y) gte_n(y, 2, prd(x, y, na.rm = TRUE), NA_real_),
  prb_no_sop = \(x, y) gte_n(y, 2, prb(x, y, na.rm = TRUE), NA_real_),
  mki_no_sop = \(x, y) gte_n(y, 2, mki(x, y, na.rm = TRUE), NA_real_),
  cod = \(x, y) gte_n(y, min_n, cod(x / y, na.rm = TRUE), NA_real_),
  cod_met = \(x, y) gte_n(y, min_n, cod_met(cod(x / y, na.rm = TRUE)), NA),
  prd = \(x, y) gte_n(y, min_n, prd(x, y, na.rm = TRUE), NA_real_),
  prd_met = \(x, y) gte_n(y, min_n, prd_met(prd(x, y, na.rm = TRUE)), NA),
  prb = \(x, y) gte_n(y, min_n, prb(x, y, na.rm = TRUE), NA_real_),
  prb_met = \(x, y) gte_n(y, min_n, prb_met(prb(x, y, na.rm = TRUE)), NA),
  mki = \(x, y) gte_n(y, min_n, mki(x, y, na.rm = TRUE), NA_real_),
  mki_met = \(x, y) gte_n(y, min_n, mki_met(mki(x, y, na.rm = TRUE)), NA)
)



ys_fns_list <- list(
  rmse        = rmse_vec,
  r_squared   = rsq_vec,
  mae         = mae_vec,
  mpe         = mpe_vec,
  mape        = mape_vec,
  mdape       = mdape_vec # From R/helpers.R
)

compute_stats <- function(data, group_var = NULL) {
  if (!is.null(group_var)) {
    data <- data %>%
      group_by(across(all_of(group_var)))
  }

  result <- data %>%
    summarize(
      num_pin_no_class = n(),
      num_sale_no_class = sum(!is.na(sale_ratio_study_price)),
      rs_lst = list(map(rs_fns_list, ~ exec(.x, pmax(pred_pin_initial_fmv, 1), sale_ratio_study_price))),
      ys_lst = list(map(ys_fns_list, ~ exec(.x, sale_ratio_study_price, pred_pin_initial_fmv))),
      median_ratio = median(pred_pin_initial_fmv / sale_ratio_study_price, na.rm = TRUE),
      .groups = ifelse(is.null(group_var), "drop", "keep")
    ) %>%
    unnest_wider(rs_lst) %>%
    unnest_wider(ys_lst)

  return(result)
}

df_stat_no_group <- compute_stats(assessment_pin)
df_stat_triad <- compute_stats(assessment_pin, "meta_triad_code")
df_stat_township <- compute_stats(assessment_pin, "meta_township_code")
df_stat_nbhd <- compute_stats(assessment_pin, "meta_nbhd_code")

df_stat_no_group_comparison <- compute_stats(assessment_pin_comparison)
df_stat_triad_comparison <- compute_stats(assessment_pin_comparison, "meta_triad_code")
df_stat_township_comparison <- compute_stats(assessment_pin_comparison, "meta_township_code")
df_stat_nbhd_comparison <- compute_stats(assessment_pin_comparison, "meta_nbhd_code")



generate_comparison_table <- function(df_new, df_comparison, group_var = NULL) {
  if (is.null(group_var)) {
    df_comparison_renamed <- df_comparison %>%
      rename_with(~ paste0(., "_new"))

    result <- bind_cols(df_new, df_comparison_renamed)
  } else {
    df_new <- df_new %>%
      rename_with(~ paste0(., "_new"), -all_of(group_var))

    result <- inner_join(df_comparison, df_new, by = group_var)
  }

  result <- result %>%
    mutate(
      rmse_pct_diff = percentage_diff(rmse, rmse_new),
      mki_pct_diff = percentage_diff(mki, mki_new),
      cod_pct_diff = percentage_diff(cod, cod_new),
      prb_pct_diff = percentage_diff(prb, prb_new),
      prd_pct_diff = percentage_diff(prd, prd_new),
      r_squared_pct_diff = percentage_diff(r_squared, r_squared_new)
    ) %>%
    select(
      if (!is.null(group_var)) all_of(group_var) else NULL,
      rmse, rmse_new, rmse_pct_diff,
      mki, mki_new, mki_pct_diff,
      cod, cod_new, cod_pct_diff,
      prb, prb_new, prb_pct_diff,
      prd, prd_new, prd_pct_diff,
      r_squared, r_squared_new, r_squared_pct_diff
    ) %>%
    mutate(across(where(is.numeric), \(x) round(x, 2)))

  datatable(result,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = FALSE
    ),
    rownames = FALSE
  )
}
```

Before running this report, make sure that the lightgbm model is set to optimize the Root Mean Square Error (RMSE). This means that the addition of a new variable *should* improve this metric. In this situation, the model sees a change of `r round(df_stat_no_group$rmse, 2)` to `r round(df_stat_no_group_comparison$rmse, 2)`, a change of `r round(df_stat_no_group$rmse - df_stat_no_group_comparison$rmse, 2)`.

RSME only describes some of the metrics that we are interested in, and it doesn't take into account changes that occur on more local levels. The tables below are split into three different geographies, triad, township, and neighborhood. Here, you can see the sortable values for each metric, and the percentage difference between the old and new models.


# Stats

::: {.panel-tabset}

## Overall

```{r}
generate_comparison_table(df_stat_no_group, df_stat_no_group_comparison)
```


## Triad

```{r}
generate_comparison_table(df_stat_triad, df_stat_triad_comparison, "meta_triad_code")
```

## Township

```{r}
generate_comparison_table(df_stat_township, df_stat_township_comparison, "meta_township_code")
```

## Neighborhood

```{r}
generate_comparison_table(df_stat_nbhd, df_stat_nbhd_comparison, "meta_nbhd_code")
```


## Range Test

Some metrics may only improve within certain ranges. For example, proximity to an amenity may only matter within 100 feet. The following table uses the param to filter the range to a minimum of `r params$min_range` and a maximum of `r params$max_range`.

```{r}
new_range <- assessment_pin %>%
  inner_join(assessment_data_small, by = "meta_pin") %>%
  mutate(!!params$added_variable := as.numeric(!!sym(params$added_variable))) %>%
  filter(!!sym(params$added_variable) > params$min_range &
    !!sym(params$added_variable) < params$max_range) %>%
  compute_stats(.)

comparison_range <- assessment_pin_comparison %>%
  inner_join(assessment_data_small, by = "meta_pin") %>%
  mutate(!!params$added_variable := as.numeric(!!sym(params$added_variable))) %>%
  filter(!!sym(params$added_variable) > params$min_range &
    !!sym(params$added_variable) < params$max_range) %>%
  compute_stats(.)

generate_comparison_table(new_range, comparison_range)
```


:::


# SHAP

The main metric that the CCAO Data team uses to assess the importance of a variable is the SHAP value. SHAP values are a way to explain the output of machine learning models. They assign the $value increase associated with each variable. The SHAP value is calculated for each observation in the dataset, and the median SHAP value is used to determine the importance of a variable. The higher the median SHAP value, the more important the variable is in the model.

## Absolute Value Rank of SHAP Scores

```{r}
shap_predictors <- unlist(metadata$model_predictor_all_name)
```

The following table produces the median absolute SHAP value by township, and creates grouped . In total, there are `r length(shap_predictors)` indicators in the model. Thus, if the median SHAP is ranked 1, it is the most important feature in a township, while if it is ranked `r length(shap_predictors)`, it is the least important feature in a township. The median value (without absolute) is also included to better contextualize the impact.


```{r shap_processing}
# Combine data
shap_df_filtered_long <- shap %>%
  inner_join(
    assessment_data %>%
      select(meta_pin, meta_card_num, meta_township_code, meta_nbhd_code) %>%
      rename(township_code = meta_township_code, neighborhood_code = meta_nbhd_code),
    by = c("meta_pin", "meta_card_num")
  ) %>%
  select(township_code, all_of(shap_predictors)) %>%
  pivot_longer(
    cols = all_of(shap_predictors),
    names_to = "feature",
    values_to = "shap"
  )

# Calculate median values for the overall data
overall_medians <- shap_df_filtered_long %>%
  group_by(feature) %>%
  summarize(
    median_abs_shap = median(abs(shap), na.rm = TRUE),
    median_shap = median(shap, na.rm = TRUE)
  ) %>%
  ungroup()

# Rank features based on median absolute SHAP values
ranked_overall_medians <- overall_medians %>%
  arrange(desc(median_abs_shap)) %>%
  mutate(rank_abs = row_number())

# Function to create summary tables
create_summary_table <- function(data, added_variable) {
  added_variable_data <- data %>%
    filter(feature == added_variable)

  if (nrow(added_variable_data) == 0) {
    return(NULL)
  }

  non_added_variable_data <- data %>%
    filter(feature != added_variable)

  combined_data <- bind_rows(added_variable_data, non_added_variable_data)

  kable_chart <- combined_data %>%
    select(feature, median_abs_shap, median_shap, rank_abs) %>%
    mutate(across(where(is.numeric), round, 2))

  datatable_chart <- datatable(kable_chart,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = FALSE
    ),
    rownames = FALSE
  )

  return(datatable_chart)
}

# Generate the overall summary table
added_variable <- params$added_variable
overall_summary_table <- create_summary_table(ranked_overall_medians, added_variable)

# Calculate median values for each township and rank features
ranked_shap_df <- shap_df_filtered_long %>%
  group_by(township_code, feature) %>%
  mutate(
    median_abs_shap = median(abs(shap), na.rm = TRUE),
    median_shap = median(shap, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  distinct(township_code, feature, .keep_all = TRUE) %>%
  group_by(township_code) %>%
  arrange(desc(median_abs_shap), .by_group = TRUE) %>%
  mutate(rank_abs = row_number()) %>%
  ungroup() %>%
  inner_join(ccao::town_dict, by = c("township_code" = "township_code"))

# Generate the township-specific tables
township_names <- unique(ranked_shap_df$township_name)
shap_tables <- lapply(township_names, function(name) {
  township_data <- ranked_shap_df %>%
    filter(township_name == name)
  create_summary_table(township_data, added_variable)
})
```


### Overall SHAP Summary
```{r shap_summary}
overall_summary_table
```


## SHAPS by Township
::: panel-tabset

### `r township_names[1]`


```{r, results = 'asis'}
shap_tables[[1]]
```
### `r township_names[2]`

```{r, results = 'asis'}
shap_tables[[2]]
```

### `r township_names[3]`


```{r, results = 'asis'}
shap_tables[[3]]
```

### `r township_names[4]`


```{r, results = 'asis'}
shap_tables[[4]]
```
### `r township_names[5]`


```{r, results = 'asis'}
shap_tables[[5]]
```

### `r township_names[6]`

```{r, results = 'asis'}
shap_tables[[6]]
```

###  `r township_names[7]`

```{r, results = 'asis'}
shap_tables[[7]]
```

###  `r township_names[8]`

```{r, results = 'asis'}
shap_tables[[8]]
```

###  `r township_names[9]`

```{r, results = 'asis'}
shap_tables[[9]]
```

###  `r township_names[10]`

```{r, results = 'asis'}
shap_tables[[10]]
```

###  `r township_names[11]`

```{r, results = 'asis'}
shap_tables[[11]]
```
###  `r township_names[12]`

```{r, results = 'asis'}
shap_tables[[12]]
```

###  `r township_names[13]`

```{r, results = 'asis'}
shap_tables[[13]]
```

###  `r township_names[14]`

```{r, results = 'asis'}
shap_tables[[14]]
```

###  `r township_names[15]`

```{r, results = 'asis'}
shap_tables[[15]]
```

###  `r township_names[16]`

```{r, results = 'asis'}
shap_tables[[16]]
```

###  `r township_names[17]`

```{r, results = 'asis'}
shap_tables[[17]]
```

###  `r township_names[18]`

```{r, results = 'asis'}
shap_tables[[18]]
```

###  `r township_names[19]`

```{r, results = 'asis'}
shap_tables[[19]]
```

###  `r township_names[20]`


```{r, results = 'asis'}
shap_tables[[20]]
```

###  `r township_names[21]`

```{r, results = 'asis'}
shap_tables[[21]]
```
###  `r township_names[22]`

```{r, results = 'asis'}
shap_tables[[22]]
```

###  `r township_names[23]`

```{r, results = 'asis'}
shap_tables[[23]]
```

###  `r township_names[24]`

```{r, results = 'asis'}
shap_tables[[24]]
```

###  `r township_names[25]`

```{r, results = 'asis'}
shap_tables[[25]]
```

###  `r township_names[26]`

```{r, results = 'asis'}
shap_tables[[26]]
```

###  `r township_names[27]`

```{r, results = 'asis'}
shap_tables[[27]]
```

###  `r township_names[28]`

```{r, results = 'asis'}
shap_tables[[28]]
```

###  `r township_names[29]`

```{r, results = 'asis'}
shap_tables[[29]]
```

###  `r township_names[30]`

```{r, results = 'asis'}
shap_tables[[30]]
```

###  `r township_names[31]`

```{r, results = 'asis'}
shap_tables[[31]]
```
###  `r township_names[32]`

```{r, results = 'asis'}
shap_tables[[32]]
```

###  `r township_names[33]`

```{r, results = 'asis'}
shap_tables[[33]]
```

###  `r township_names[34]`

```{r, results = 'asis'}
shap_tables[[34]]
```

###  `r township_names[35]`

```{r, results = 'asis'}
shap_tables[[35]]
```

###  `r township_names[36]`

```{r, results = 'asis'}
shap_tables[[36]]
```

###  `r township_names[37]`

```{r, results = 'asis'}
shap_tables[[37]]
```

###  `r township_names[38]`

```{r, results = 'asis'}
shap_tables[[38]]
```

:::


## Correlation between SHAP and the Added Variable

```{r shap_variable_correlation}
correlation_value <- cor(pull(working_data, params$added_variable_shap), pull(working_data, params$added_variable), use = "complete.obs")
```

One way to test if the added feature is improving the model, is to see if there is a relationship between the SHAP values and the added values. The assumption would be, that if the added value caused an increase / decrease in assessed values, then the correlation would be high in a positive or negative value. In this case, the correlation between the SHAP values and the added variable is `r round(correlation_value, 2)`.


# Spatial Analysis

The spatial analysis is broken up into a few sections. The first panel looks at four aggregated stats on the neighborhood level, the mean of the variable we are analyzing, the mean of the asbolute value of the SHAP, the 90th percentile of the SHAP, and the change in FMV based on the added variable. 

## Neighborhood Values

::: panel-tabset

### Mean Variable

```{r mean_variable}
spatial_data %>%
  ggplot() +
  geom_sf(aes(fill = !!sym(paste0(params$added_variable, "_neighborhood_mean")))) +
  scale_fill_viridis_c(option = "viridis", name = "Value") +
  theme_void() +
  coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
```

### Mean Absolute SHAP

```{r mean_shap}
spatial_data %>%
  ggplot() +
  geom_sf(aes(fill = !!sym(paste0(params$added_variable_shap, "_neighborhood_mean")))) +
  scale_fill_viridis_c(option = "viridis", name = "Value") +
  theme_void() +
  coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
```

### 90th Percentile of Absolute SHAP

```{r 90th_percentile_shap}
spatial_data %>%
  ggplot() +
  geom_sf(aes(fill = !!sym(paste0(params$added_variable_shap, "_neighborhood_90th")))) +
  scale_fill_viridis_c(option = "viridis", name = "Value") +
  theme_void() +
  coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
```

### Median change in Neighborhood FMV

```{r neighborhood_change}
assessment_pin %>%
  select(meta_pin, loc_longitude, loc_latitude, pred_pin_final_fmv) %>%
  rename(pred_pin_final_fmv_new = pred_pin_final_fmv) %>%
  inner_join(assessment_pin_comparison, by = "meta_pin") %>%
  rename(pred_pin_final_fmv_comparison = pred_pin_final_fmv) %>%
  group_by(meta_nbhd_code) %>%
  summarize(
    median_fmv_new = median(pred_pin_final_fmv_new),
    median_fmv_comparison = median(pred_pin_final_fmv_comparison),
    fmv_ratio = (median_fmv_new / median_fmv_comparison) / median_fmv_comparison
  ) %>%
  inner_join(nbhd, by = c("meta_nbhd_code" = "town_nbhd")) %>%
  st_as_sf() %>%
  ggplot() +
  geom_sf(aes(fill = fmv_ratio)) +
  scale_fill_viridis_c(option = "viridis", name = "fmv_ratio") +
  theme_void() +
  coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
```

:::


```{r leaflet_function}
create_leaflet_map <- function(dataset, legend_value, legend_title, longitude = "loc_longitude", latitude = "loc_latitude") {
  # Create the color palette
  pal <- colorNumeric(palette = "Reds", domain = dataset[[legend_value]])

  # Create the leaflet map
  leaflet(dataset) %>%
    addTiles() %>%
    addCircleMarkers(
      lng = ~ get(longitude),
      lat = ~ get(latitude),
      radius = 5,
      color = ~ pal(dataset[[legend_value]]),
      popup = ~ paste(
        "<br>", "Pin: ", dataset$meta_pin,
        "<br>", "SHAP:", sprintf("%.2f", dataset[[params$added_variable_shap]]),
        "<br>", "Variable:", sprintf("%.2f", dataset[[params$added_variable]]),
        "<br>", "New FMV:", dataset$pred_pin_final_fmv_new,
        "<br>", "Comparison FMV: ", dataset$pred_pin_final_fmv_comparison,
        "<br>", "FMV Difference: ", dataset$diff_pred_pin_final_fmv
      )
    ) %>%
    addLegend(
      "bottomright",
      pal = pal,
      values = ~ dataset[[legend_value]],
      title = legend_title
    )
}
```

## Mapping the Highest and Lowest 100 Values
From here, we look at three different types of high and low values; the values of the variable we are analyzing, the impact that can be determined through the SHAPs, and the largest effects in change in FMV. Be careful interpreting values which are the max and min of the raw value, since ties are not accounted for. For example, if there are 10,000 parcels which are 0 feet from a newly constructed building, the map will not be a full representation. 

::: panel-tabset

### Largest 100 Values

```{r}
highest_100 <- working_data %>%
  arrange(desc(!!sym(params$added_variable))) %>%
  slice(1:100)

create_leaflet_map(highest_100, params$added_variable, "Largest 100 Values")
```

### Lowest 100 Values

```{r}
lowest_100 <- working_data %>%
  arrange(!!sym(params$added_variable)) %>%
  slice(1:100)

create_leaflet_map(lowest_100, params$added_variable, "Lowest 100 Values")
```

### Highest 100 SHAP Values

```{r}
highest_100 <- working_data %>%
  arrange(desc(!!sym(params$added_variable_shap))) %>%
  slice(1:100)

create_leaflet_map(highest_100, params$added_variable_shap, "Highest 100 SHAPs")
```

### Lowest 100 SHAP Values

```{r}
# Example usage with the dataset sliced outside the function
lowest_100 <- working_data %>%
  arrange(!!sym((params$added_variable_shap))) %>%
  slice(1:100)

create_leaflet_map(lowest_100, params$added_variable_shap, "Lowest 100 SHAPs")
```

### 100 Largest FMV Increases
```{r}
largest_fmv_increases <- working_data %>%
  arrange(desc(diff_pred_pin_final_fmv)) %>%
  slice(1:100)

# Call the function with the pre-sliced dataset
create_leaflet_map(largest_fmv_increases, "diff_pred_pin_final_fmv", "Largest FMV Increases")
```

### 100 Largest FMV Decreases

```{r}
largest_fmv_decreases <- working_data %>%
  arrange(diff_pred_pin_final_fmv) %>%
  slice(1:100)

create_leaflet_map(largest_fmv_decreases, "diff_pred_pin_final_fmv", "Largest FMV Decreases")
```

:::

## Neighborhoods with the Highest and Lowest SHAP Values

These maps identify neighborhoods where the added variable is having the largest impact on SHAP values. By selecting neighborhoods with the highest mean(absolute value), you can take a closer look at how individual houses in these neighborhoods are affected.

::: panel-tabset
```{r processing_SHAP_values}
working_data <- working_data %>%
  group_by(meta_nbhd_code) %>%
  mutate(
    mean_value = mean(abs(!!sym(paste0(params$added_variable_shap))), na.rm = TRUE)
  ) %>%
  ungroup()

selected_neighborhoods <- working_data %>%
  distinct(meta_nbhd_code, .keep_all = TRUE) %>%
  arrange(mean_value) %>%
  slice(c(1:2, (n() - 1):n())) %>%
  pull(meta_nbhd_code)

# Filter the data to include only the selected neighborhoods
selected_data <- working_data %>%
  filter(meta_nbhd_code %in% selected_neighborhoods)

# Separate high and low standard deviation neighborhoods
high_mean_data <- selected_data %>%
  filter(meta_nbhd_code %in% selected_neighborhoods[(length(selected_neighborhoods) - 1):length(selected_neighborhoods)])

low_mean_data <- selected_data %>%
  filter(meta_nbhd_code %in% selected_neighborhoods[1:2])
```

### 2 Lowest SHAP Neighborhoods

```{r}
create_leaflet_map(low_mean_data, params$added_variable_shap, "SHAP Values")
```

### 2 Highest SHAP Neighborhoods

```{r}
create_leaflet_map(high_mean_data, params$added_variable_shap, "SHAP Values")
```

:::


## Within Neighborhood Largest Values

Disparities may also be seen at the individual house level, and may be present within neighborhoods of all types, we select the top and bottom 10 SHAP values for each neighborhood. Because neighborhoods with *very* high FMVs have comparatively higher SHAP values, we also create a relative score, which can be understood as what percentage of the houses value is determined by this variable. This allows a comparison of within-neighborhood impact, while accounting for intra-neighborhood differences.

::: panel-tabset

### 10 Highest SHAP Values per Neighborhood

```{r}
top_10_data <- working_data %>%
  group_by(meta_nbhd_code) %>%
  top_n(10, wt = !!sym(paste0(params$added_variable_shap))) %>%
  ungroup()


create_leaflet_map(top_10_data, params$added_variable_shap, "SHAP Values")
```

### 10 Lowest SHAP values per neighborhood

```{r}
bottom_10_data <- working_data %>%
  group_by(meta_nbhd_code) %>%
  top_n(-10, wt = !!sym(paste0(params$added_variable_shap))) %>%
  ungroup()

create_leaflet_map(bottom_10_data, params$added_variable_shap, "SHAP Values")
```

### 10 Highest Relative SHAP values per neighborhood

```{r}
top_10_data_relative <- working_data %>%
  mutate(shap_relative_value = !!sym(params$added_variable_shap) / median_card_value) %>%
  group_by(meta_nbhd_code) %>%
  top_n(10, wt = shap_relative_value) %>%
  ungroup()


create_leaflet_map(top_10_data_relative, params$added_variable_shap, "Relative SHAP Values")
```
### Bottom 10 Relative SHAP Values per Neighborhood
```{r}
bottom_10_data_relative <- working_data %>%
  mutate(shap_relative_value = !!sym(params$added_variable_shap) / median_card_value) %>%
  group_by(meta_nbhd_code) %>%
  top_n(-10, wt = shap_relative_value) %>%
  ungroup()

create_leaflet_map(bottom_10_data_relative, params$added_variable_shap, "Relative SHAP Values")
```

:::

# Deciding on the Use of a New Variable

Feature selection for the lightgbm model is not as straightforward as selecting the statistical significant variables, and because we need interpretable results, all variables should represent a defined and understandable cause of for a change in estimated FMV (i.e., no dimension reduction). In general, the lightgbm model does a good job of basing the results on the most important features, meaning that the inclusion process can be inclusive rather than exclusive.


Because of this, to deem that the added feature is not relevant, it should

- Not improve model metrics
- Be one of the lowest SHAP value indicators
- Not have effects in particular neighborhoods

Other metrics can be used to guide this, but are not a pre-requisite.

- There is little correlation between SHAP values and the variable
- The variable is highly correlated with another existing variable.
