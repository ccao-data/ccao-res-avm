---
title: "New Feature Template"
subtitle: "Run ID: `r params$added_feature`: `r params$description`"
date: "`r Sys.Date()`"
author: "Cook County Assessor's Office Data Department"
execute:
  echo: false
  warning: false
  asis: true
format:
  html:
    embed-resources: true
    toc: true
    toc_float: true
    fig-align: center
    fontsize: 12pt
params:
  run_id: "2024-07-03-charming-boni"
  run_id_year: "2024"
  comparison_run_id: "2024-07-09-cool-takuya"
  comparison_run_id_year: "2024"
  added_feature: "ccao_is_corner_lot" 
  added_feature_shap: "ccao_is_corner_lot_shap"
  description: "A distance in feet to the nearest new construction"
  min_range: 5
  max_range: 95
  type: "categorical"
---

```{r packages}
library(purrr)
library(here)
library(yaml)
library(corrplot)
# Load list of helper files and main libraries
purrr::walk(list.files(here::here("R"), "\\.R$", full.names = TRUE), source)

# Load reporting-only R libraries
suppressPackageStartupMessages({
  reporting_libs <- "Config/renv/profiles/reporting/dependencies"
  purrr::walk(
    strsplit(read_yaml(here::here("DESCRIPTION"))[[reporting_libs]], ", ")[[1]],
    library,
    character.only = TRUE
  )
})

# TODO: Catch for weird Arrow bug with SIGPIPE. Need to permanently fix later
# https://github.com/apache/arrow/issues/32026
cpp11::cpp_source(code = "
#include <csignal>
#include <cpp11.hpp>

[[cpp11::register]] void ignore_sigpipes() {
  signal(SIGPIPE, SIG_IGN);
}
")

ignore_sigpipes()

# Initialize a dictionary of file paths. See misc/file_dict.csv for details
paths <- model_file_dict(model_params$run_id, model_params$year)
```

```{r download_new_data}
analyses_paths <- list(
  output = list(
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/performance/year=", params$run_id_year, "/stage=assessment/", params$run_id, ".parquet"),
      key = "performance"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/metadata/year=", params$run_id_year, "/", params$run_id, ".parquet"),
      key = "metadata"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/shap/year=", params$run_id_year, "/run_id=", params$run_id, "/"),
      key = "shap"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/assessment_card/year=", params$run_id_year, "/run_id=", params$run_id, "/"),
      key = "assessment_card"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/assessment_pin/year=", params$run_id_year, "/run_id=", params$run_id, "/"),
      key = "assessment_pin"
    )
  )
)

fetch_analyses <- function(run_id, year, analyses_paths) {
  tictoc::tic(paste0("Fetched run: ", run_id))

  s3_objs <- grep("s3://", unlist(analyses_paths$output), value = TRUE)
  bucket <- strsplit(s3_objs[1], "/")[[1]][3]

  data_list <- list()

  for (analyses_path in analyses_paths$output) {
    is_directory <- endsWith(analyses_path$s3, "/")
    if (is_directory) {
      partitioned_by_run <- endsWith(analyses_path$s3, paste0("run_id=", run_id, "/"))
      if (partitioned_by_run) {
        dir_path <- analyses_path$s3
      } else {
        dir_path <- paste0(analyses_path$s3, "year=", year, "/run_id=", run_id, "/")
      }

      message("Now fetching: ", dir_path)
      objs_prefix <- sub(paste0("s3://", bucket, "/"), "", dir_path)
      objs <- aws.s3::get_bucket_df(bucket, objs_prefix)
      objs <- dplyr::filter(objs, Size > 0)

      if (nrow(objs) > 0) {
        combined_data <- NULL
        for (key in objs$Key) {
          message("Now fetching: ", key)
          local_temp_path <- file.path(tempdir(), basename(key))
          aws.s3::save_object(key, bucket = bucket, file = local_temp_path)

          # Read the Parquet file and append it to combined_data
          temp_data <- arrow::read_parquet(local_temp_path)
          if (is.null(combined_data)) {
            combined_data <- temp_data
          } else {
            combined_data <- dplyr::bind_rows(combined_data, temp_data)
          }
        }
        data_list[[analyses_path$key]] <- combined_data
      } else {
        warning(analyses_path$key, " does not exist for this run")
      }
    } else {
      message("Now fetching: ", analyses_path$s3)
      if (aws.s3::object_exists(analyses_path$s3, bucket = bucket)) {
        local_temp_path <- file.path(tempdir(), basename(analyses_path$s3))
        aws.s3::save_object(analyses_path$s3, bucket = bucket, file = local_temp_path)
        data_list[[analyses_path$key]] <- arrow::read_parquet(local_temp_path)
      } else {
        warning(analyses_path$key, " does not exist for this run")
      }
    }
  }

  tictoc::toc()
  return(data_list)
}

data <- fetch_analyses(params$run_id, params$run_id_year, analyses_paths)

performance <- data$performance
metadata <- data$metadata
shap <- data$shap
assessment_card <- data$assessment_card %>%
  select(meta_pin, meta_card_num, pred_card_initial_fmv, meta_nbhd_code, meta_township_code, !!sym(params$added_feature))

assessment_pin <- data$assessment_pin

lockfile_assessment <- metadata$dvc_md5_assessment_data

# Define S3 paths for assessment and training data
s3_path_assessment <- paste0(
  "s3://ccao-data-dvc-us-east-1/files/md5/",
  substr(lockfile_assessment, 1, 2), "/",
  substr(lockfile_assessment, 3, nchar(lockfile_assessment))
)


assessment_data <- s3read_using(FUN = read_parquet, object = s3_path_assessment)
```

```{r download_comparison_data}
analyses_paths <- list(
  output = list(
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/performance/year=", params$comparison_run_id_year, "/stage=assessment/", params$comparison_run_id, ".parquet"),
      key = "performance"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/assessment_pin/year=", params$comparison_run_id_year, "/run_id=", params$comparison_run_id, "/"),
      key = "assessment_pin"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/shap/year=", params$comparison_run_id_year, "/run_id=", params$comparison_run_id, "/"),
      key = "shap"
    ),
    list(
      s3 = paste0("s3://ccao-model-results-us-east-1/metadata/year=", params$comparison_run_id_year, "/", params$comparison_run_id, ".parquet"),
      key = "metadata"
    )
  )
)

data_comparison <- fetch_analyses(params$comparison_run_id, params$comparison_run_id_year, analyses_paths)

metadata_comparison <- data_comparison$metadata
model_performance_assessment_comparison <- data_comparison$performance
shap_comparison <- data_comparison$shap

assessment_pin_comparison <- data_comparison$assessment_pin %>%
  select(meta_pin, pred_pin_final_fmv, sale_ratio_study_price, meta_nbhd_code, meta_triad_code, pred_pin_initial_fmv, meta_township_code)
```

```{r}
# write_parquet(assessment_data, "assessment_data.parquet")
# write_parquet(assessment_pin, "assessment_pin.parquet")
# write_parquet(assessment_card, "assessment_card.parquet")
# write_parquet(performance, "performance.parquet")
# write_parquet(shap, "shap.parquet")
# write_parquet(metadata, "metadata.parquet")
# write_parquet(assessment_pin_comparison, "assessment_pin_comparison.parquet")
# write_parquet(model_performance_assessment_comparison, "model_performance_assessment_comparison.parquet")
# write_parquet(shap_comparison, "shap_comparison.parquet")
# write_parquet(metadata_comparison, "metadata_comparison.parquet")
```

```{r}
# assessment_data <- read_parquet("assessment_data.parquet")
# assessment_pin <- read_parquet("assessment_pin.parquet")
# assessment_card <- read_parquet("assessment_card.parquet")
# performance <- read_parquet("performance.parquet")
# shap <- read_parquet("shap.parquet")
# metadata <- read_parquet("metadata.parquet")
# assessment_pin_comparison <- read_parquet("assessment_pin_comparison.parquet")
# model_performance_assessment_comparison <- read_parquet("model_performance_assessment_comparison.parquet")
# shap_comparison <- read_parquet("shap_comparison.parquet")
# metadata_comparison <- read_parquet("metadata_comparison.parquet")
```



```{r data_processing}
assessment_data_small <- assessment_data %>%
  select(meta_pin, meta_card_num, meta_nbhd_code, loc_longitude, loc_latitude, meta_township_name, !!sym(params$added_feature))

# Create a card level dataset

working_data_card <- shap %>%
  select(meta_pin, meta_card_num, pred_card_shap_baseline_fmv, !!sym(params$added_feature)) %>%
  rename(!!sym(params$added_feature_shap) := !!sym(params$added_feature)) %>%
  inner_join(assessment_card, by = c("meta_pin", "meta_card_num")) %>%
  group_by(meta_nbhd_code) %>%
  mutate(!!paste0(params$added_feature, "_shap_neighborhood_mean") := mean(abs(!!sym(params$added_feature_shap)), na.rm = TRUE),
    !!paste0(params$added_feature, "_shap_neighborhood_90th") := quantile(abs(!!sym(params$added_feature_shap)), 0.9, na.rm = TRUE),
    mean_value_shap = mean(abs(!!sym(params$added_feature_shap)), na.rm = TRUE),
    median_card_value = median(pred_card_initial_fmv, na.rm = TRUE),
    shap_relative = percent((!!sym(params$added_feature_shap) / pred_card_initial_fmv), accuracy = 0.01),
  ) %>%
  ungroup()


working_data_pin <- assessment_data_small %>%
  group_by(meta_nbhd_code) %>%
  mutate(
    !!paste0(params$added_feature, "_neighborhood_mean") := mean(!!sym(params$added_feature), na.rm = TRUE),
    !!paste0(params$added_feature, "_neighborhood_median") := median(!!sym(params$added_feature), na.rm = TRUE),
    !!paste0(params$added_feature, "_neighborhood_90th") := quantile(!!sym(params$added_feature), 0.9, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  inner_join(assessment_pin %>% select(meta_pin, pred_pin_final_fmv, pred_pin_initial_fmv), by = "meta_pin") %>%
  rename(
    pred_pin_final_fmv_new = pred_pin_final_fmv,
    pred_pin_initial_fmv_new = pred_pin_initial_fmv
  ) %>%
  inner_join(assessment_pin_comparison %>% select(meta_pin, pred_pin_final_fmv, pred_pin_initial_fmv), by = "meta_pin") %>%
  rename(
    pred_pin_final_fmv_comp = pred_pin_final_fmv,
    pred_pin_initial_fmv_comp = pred_pin_initial_fmv
  ) %>%
  mutate(
    diff_pred_pin_final_fmv = round(pred_pin_final_fmv_new - pred_pin_final_fmv_comp, 2),
    pred_pin_final_fmv_new = scales::dollar(pred_pin_final_fmv_new),
    pred_pin_final_fmv_comparison = scales::dollar(pred_pin_final_fmv_comp),
    diff_pred_pin_initial_fmv = round(pred_pin_initial_fmv_new - pred_pin_initial_fmv_comp, 2),
    pred_pin_initial_fmv_new = scales::dollar(pred_pin_initial_fmv_new),
    pred_pin_initial_fmv_comp = scales::dollar(pred_pin_initial_fmv_comp)
  )

nbhd <- ccao::nbhd_shp

spatial_data_card <- working_data_card %>%
  distinct(meta_nbhd_code, .keep_all = TRUE) %>%
  inner_join(nbhd, by = c("meta_nbhd_code" = "town_nbhd")) %>%
  st_as_sf()

spatial_data_pin <- working_data_pin %>%
  distinct(meta_nbhd_code, .keep_all = TRUE) %>%
  inner_join(nbhd, by = c("meta_nbhd_code" = "town_nbhd")) %>%
  st_as_sf()
```

# Descriptive Statistics

Based on the params$type feature, charts with the mean and median values of the feature are displayed for continuous features, and the percentage of each category is displayed for categorical features. These tables are broken down by township and neighborhood.


::: {.panel-tabset}


## Overall

```{r mean_median}
if (params$type == "continuous") {
  descriptives <- working_data_pin %>%
    summarize(
      mean = round(mean(!!sym(params$added_feature), na.rm = TRUE), 2),
      median = round(median(!!sym(params$added_feature), na.rm = TRUE), 2)
    )

  datatable(descriptives,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )
} else if (params$type == "categorical") {
  category_percentages_township <- working_data_pin %>%
    count(meta_township_name, !!sym(params$added_feature)) %>%
    mutate(percentage = round(n / sum(n) * 100, 2)) %>%
    select(meta_township_name, !!sym(params$added_feature), percentage) %>%
    pivot_wider(names_from = !!sym(params$added_feature), values_from = percentage, values_fill = list(percentage = 0))

  datatable(category_percentages_township,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )
}
```

## Township
```{r mean_median_township}
if (params$type == "continuous") {
  descriptives_township <- working_data_pin %>%
    group_by(meta_township_name) %>%
    summarize(
      mean = round(mean(!!sym(params$added_feature), na.rm = TRUE), 2),
      median = round(median(!!sym(params$added_feature), na.rm = TRUE), 2)
    )

  datatable(descriptives_township,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )
} else if (params$type == "categorical") {
  category_percentages_township <- working_data_pin %>%
    group_by(meta_township_name, !!sym(params$added_feature)) %>%
    count() %>%
    group_by(meta_township_name) %>%
    mutate(percentage = round(n / sum(n) * 100, 2)) %>%
    select(meta_township_name, !!sym(params$added_feature), percentage) %>%
    pivot_wider(names_from = !!sym(params$added_feature), values_from = percentage, values_fill = list(percentage = 0))


  datatable(category_percentages_township,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )
}
```

## Neighborhood

```{r mean_median_neighborhood}
if (params$type == "continuous") {
  descriptives_nbhd <- working_data_pin %>%
    group_by(meta_nbhd_code) %>%
    summarize(
      mean = round(mean(!!sym(params$added_feature), na.rm = TRUE), 2),
      median = round(median(!!sym(params$added_feature), na.rm = TRUE), 2)
    )

  datatable(descriptives_nbhd,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )
} else if (params$type == "categorical") {
  category_percentages_nbhd <- working_data_pin %>%
    group_by(meta_nbhd_code, !!sym(params$added_feature)) %>%
    count() %>%
    mutate(percentage = n / sum(n) * 100) %>%
    select(meta_nbhd_code, !!sym(params$added_feature), percentage)

  datatable(category_percentages_nbhd,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )
}
```


:::

## Histogram

```{r histogram}
if (params$type == "continuous") {
  working_data_pin %>%
    mutate(
      mean_value = mean(!!sym(params$added_feature), na.rm = TRUE),
      median_value = median(!!sym(params$added_feature), na.rm = TRUE)
    ) %>%
    ggplot(aes(x = !!sym(params$added_feature))) +
    geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
    geom_vline(aes(xintercept = mean_value, color = "Mean"), linetype = "dashed", linewidth = 1, show.legend = TRUE) +
    geom_vline(aes(xintercept = median_value, color = "Median"), linetype = "dashed", linewidth = 1, show.legend = TRUE) +
    scale_color_manual(
      name = "Statistics",
      values = c(Mean = "red", Median = "green"),
      labels = c("Mean", "Median")
    ) +
    labs(
      title = paste("Histogram of", params$added_feature),
      x = params$added_feature,
      y = "Frequency"
    ) +
    theme_minimal()
} else if (params$type == "categorical") {
  category_percentages <- working_data_pin %>%
    count(!!sym(params$added_feature)) %>%
    mutate(percentage = n / sum(n) * 100)

  ggplot(category_percentages, aes(x = !!sym(params$added_feature), y = percentage)) +
    geom_bar(stat = "identity", fill = "blue", color = "black", alpha = 0.7) +
    labs(
      title = paste("Bar Chart of", params$added_feature),
      x = params$added_feature,
      y = "Percentage"
    ) +
    theme_minimal()
}
```


## FMV Change Histogram

This chart shows the distribution of the value of 'diff_pred_pin_initial_fmv' in the model with the added feature minus the model without the added feature. Outliers outside of 95% are removed to make the chart more readable. The largest 100 increases and decreases are displayed in maps in section X. 
```{r}
working_data_pin %>%
  filter(
    diff_pred_pin_initial_fmv >= quantile(diff_pred_pin_initial_fmv, 0.025, na.rm = TRUE) &
      diff_pred_pin_initial_fmv <= quantile(diff_pred_pin_initial_fmv, 0.975, na.rm = TRUE)
  ) %>%
  mutate(
    mean_value = mean(diff_pred_pin_initial_fmv, na.rm = TRUE),
    median_value = median(diff_pred_pin_initial_fmv, na.rm = TRUE)
  ) %>%
  ggplot(aes(x = diff_pred_pin_initial_fmv)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
  geom_vline(aes(xintercept = mean_value, color = "Mean"), linetype = "dashed", linewidth = 1, show.legend = TRUE) +
  geom_vline(aes(xintercept = median_value, color = "Median"), linetype = "dashed", linewidth = 1, show.legend = TRUE) +
  scale_color_manual(
    name = "Statistics",
    values = c(Mean = "red", Median = "green"),
    labels = c("Mean", "Median")
  ) +
  labs(
    x = "Change in FMV",
    y = "Frequency"
  ) +
  theme_minimal()
```

## SHAP Histogram

```{r}
shap %>%
  filter(
    !!sym(params$added_feature) >= quantile(!!sym(params$added_feature), 0.025, na.rm = TRUE) &
      !!sym(params$added_feature) <= quantile(!!sym(params$added_feature), 0.975, na.rm = TRUE)
  ) %>%
  mutate(
    mean_value = mean(!!sym(params$added_feature), na.rm = TRUE),
    median_value = median(!!sym(params$added_feature), na.rm = TRUE)
  ) %>%
  ggplot(aes(x = !!sym(params$added_feature))) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
  geom_vline(aes(xintercept = mean_value, color = "Mean"), linetype = "dashed", linewidth = 1, show.legend = TRUE) +
  geom_vline(aes(xintercept = median_value, color = "Median"), linetype = "dashed", linewidth = 1, show.legend = TRUE) +
  scale_color_manual(
    name = "Statistics",
    values = c(Mean = "red", Median = "green"),
    labels = c("Mean", "Median")
  ) +
  labs(
    x = "SHAP Value",
    y = "Frequency"
  ) +
  theme_minimal()
```

:::

## Correlation between Added feature and Other features

Here, the goal is to see if the added feature *very* neatly aligns with other existing features. Columns are produced with both the absolute value of the correlation (for easy sorting), as well as the correlation to help decipher the direction of the relationship.

```{r correlation between features}
clean_column_values <- function(df, column_name) {
  df[[column_name]] <- df[[column_name]] %>%
    gsub("^meta_|^prox_|^other_|^loc_|^char_|^acs5|^acs_|^ccao_", "", .) %>%
    gsub("_", " ", .)
  return(df)
}

columns_to_remove <- c(
  "time_sale_year",
  "time_sale_month_of_year",
  "time_sale_day_of_year",
  "time_sale_day_of_week",
  "time_sale_day_of_month",
  "time_sale_day"
)

if (params$type == "continuous") {
  # Select only numeric columns from assessment_data and remove the specified columns
  numeric_cols <- assessment_data %>%
    select_if(is.numeric) %>%
    select(-all_of(columns_to_remove))

  # Initialize a data frame to store correlation results
  correlation_results <- data.frame(Feature = character(), Correlation = numeric(), Abs_Correlation = numeric(), stringsAsFactors = FALSE)

  # Loop through each numeric column and calculate correlation and absolute correlation
  for (col_name in names(numeric_cols)) {
    # Filter out rows with missing values in the two columns being compared
    complete_cases <- complete.cases(numeric_cols[[col_name]], assessment_data[[params$added_feature]])

    # Only compute correlation if there are complete cases
    if (sum(complete_cases) > 0) {
      correlation_value <- cor(numeric_cols[[col_name]][complete_cases], assessment_data[[params$added_feature]][complete_cases], use = "complete.obs")
      abs_correlation_value <- abs(cor(abs(numeric_cols[[col_name]][complete_cases]), abs(assessment_data[[params$added_feature]][complete_cases]), use = "complete.obs"))
      correlation_results <- rbind(correlation_results, data.frame(Feature = col_name, Correlation = correlation_value, Abs_Correlation = abs_correlation_value))
    }
  }

  # Sort the correlation results in descending order by Correlation
  correlation_results <- correlation_results %>%
    arrange(dplyr::desc(Abs_Correlation)) %>%
    mutate(across(where(is.numeric), ~ round(., 2)))

  top_10_features <- correlation_results %>%
    slice(1:10) %>%
    pull(Feature)

  correlation_results_clean <- clean_column_values(correlation_results, "Feature") %>%
    slice(2:n())

  # Display the correlation results as a scrollable table
  datatable(correlation_results_clean, options = list(scrollX = TRUE, scrollY = TRUE, pageLength = 10, order = list(list(1, "desc"))))
} else {
  print(paste("assessment_data$", params$added_feature, " is not numeric.", sep = ""))
}
```

## Correlation Matrix

```{r}
assessment_data %>%
  select(all_of(top_10_features)) %>%
  na.omit() %>%
  rename_with(~ gsub("^meta_|^prox_|^other_|^loc_|^char_|^acs5|^acs_|^ccao_", "", .)) %>%
  rename_with(~ gsub("_", " ", .)) %>%
  cor() %>%
  corrplot()
```

# Overview of Model Metrics

```{r model_stats}
# Function to calculate the percentage difference
percentage_diff <- function(x, y) {
  scales::percent((y - x) / x)
}


min_n <- 10

gte_n <- \(n_sales, min_n, fn, na_type) {
  ifelse(sum(!is.na(n_sales)) >= min_n, fn, na_type)
}
rs_fns_list <- list(
  cod_no_sop = \(x, y) gte_n(y, 2, cod(x / y, na.rm = TRUE), NA_real_),
  prd_no_sop = \(x, y) gte_n(y, 2, prd(x, y, na.rm = TRUE), NA_real_),
  prb_no_sop = \(x, y) gte_n(y, 2, prb(x, y, na.rm = TRUE), NA_real_),
  mki_no_sop = \(x, y) gte_n(y, 2, mki(x, y, na.rm = TRUE), NA_real_),
  cod = \(x, y) gte_n(y, min_n, cod(x / y, na.rm = TRUE), NA_real_),
  cod_met = \(x, y) gte_n(y, min_n, cod_met(cod(x / y, na.rm = TRUE)), NA),
  prd = \(x, y) gte_n(y, min_n, prd(x, y, na.rm = TRUE), NA_real_),
  prd_met = \(x, y) gte_n(y, min_n, prd_met(prd(x, y, na.rm = TRUE)), NA),
  prb = \(x, y) gte_n(y, min_n, prb(x, y, na.rm = TRUE), NA_real_),
  prb_met = \(x, y) gte_n(y, min_n, prb_met(prb(x, y, na.rm = TRUE)), NA),
  mki = \(x, y) gte_n(y, min_n, mki(x, y, na.rm = TRUE), NA_real_),
  mki_met = \(x, y) gte_n(y, min_n, mki_met(mki(x, y, na.rm = TRUE)), NA)
)



ys_fns_list <- list(
  rmse        = rmse_vec,
  r_squared   = rsq_vec,
  mae         = mae_vec,
  mpe         = mpe_vec,
  mape        = mape_vec,
  mdape       = mdape_vec # From R/helpers.R
)

compute_stats <- function(data, group_var = NULL) {
  if (!is.null(group_var)) {
    data <- data %>%
      group_by(across(all_of(group_var)))
  }

  result <- data %>%
    summarize(
      num_pin_no_class = n(),
      num_sale_no_class = sum(!is.na(sale_ratio_study_price)),
      rs_lst = list(map(rs_fns_list, ~ exec(.x, pmax(pred_pin_initial_fmv, 1), sale_ratio_study_price))),
      ys_lst = list(map(ys_fns_list, ~ exec(.x, sale_ratio_study_price, pred_pin_initial_fmv))),
      median_ratio = median(pred_pin_initial_fmv / sale_ratio_study_price, na.rm = TRUE),
      .groups = ifelse(is.null(group_var), "drop", "keep")
    ) %>%
    unnest_wider(rs_lst) %>%
    unnest_wider(ys_lst)

  return(result)
}

df_stat_no_group <- compute_stats(assessment_pin)
df_stat_triad <- compute_stats(assessment_pin, "meta_triad_code")
df_stat_township <- compute_stats(assessment_pin, "meta_township_code")
df_stat_nbhd <- compute_stats(assessment_pin, "meta_nbhd_code")

df_stat_no_group_comparison <- compute_stats(assessment_pin_comparison)
df_stat_triad_comparison <- compute_stats(assessment_pin_comparison, "meta_triad_code")
df_stat_township_comparison <- compute_stats(assessment_pin_comparison, "meta_township_code")
df_stat_nbhd_comparison <- compute_stats(assessment_pin_comparison, "meta_nbhd_code")



generate_comparison_table <- function(df_new, df_comparison, group_var = NULL) {
  if (is.null(group_var)) {
    df_comparison_renamed <- df_comparison %>%
      rename_with(~ paste0(., "_new"))

    result <- bind_cols(df_new, df_comparison_renamed)
  } else {
    df_new <- df_new %>%
      rename_with(~ paste0(., "_new"), -all_of(group_var))

    result <- inner_join(df_comparison, df_new, by = group_var)
  }

  result <- result %>%
    mutate(
      rmse_pct_diff = percentage_diff(rmse, rmse_new),
      mki_pct_diff = percentage_diff(mki, mki_new),
      cod_pct_diff = percentage_diff(cod, cod_new),
      prb_pct_diff = percentage_diff(prb, prb_new),
      prd_pct_diff = percentage_diff(prd, prd_new),
      r_squared_pct_diff = percentage_diff(r_squared, r_squared_new)
    ) %>%
    select(
      if (!is.null(group_var)) all_of(group_var) else NULL,
      rmse, rmse_new, rmse_pct_diff,
      mki, mki_new, mki_pct_diff,
      cod, cod_new, cod_pct_diff,
      prb, prb_new, prb_pct_diff,
      prd, prd_new, prd_pct_diff,
      r_squared, r_squared_new, r_squared_pct_diff
    ) %>%
    mutate(across(where(is.numeric), \(x) round(x, 2)))

  datatable(result,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )
}
```

Before running this report, make sure that the lightgbm model is set to optimize the Root Mean Square Error (RMSE). This means that the addition of a new feature *should* improve this metric. In this situation, the model sees a change of `r round(df_stat_no_group$rmse, 2)` to `r round(df_stat_no_group_comparison$rmse, 2)`, a change of `r round(df_stat_no_group$rmse - df_stat_no_group_comparison$rmse, 2)`.

Below are other features, organized by different geographies to see if the the added feature improves other metrics that the office is interested in. 


# Stats

::: {.panel-tabset}

## Overall

```{r}
generate_comparison_table(df_stat_no_group, df_stat_no_group_comparison)
```


## Triad

```{r}
generate_comparison_table(df_stat_triad, df_stat_triad_comparison, "meta_triad_code")
```

## Township

```{r}
generate_comparison_table(df_stat_township, df_stat_township_comparison, "meta_township_code")
```

## Neighborhood

```{r}
generate_comparison_table(df_stat_nbhd, df_stat_nbhd_comparison, "meta_nbhd_code")
```


## Range Test

Some metrics may only improve within certain ranges. For example, proximity to an amenity may only matter within 100 feet. The following table uses the param to filter the range to a minimum of `r params$min_range` and a maximum of `r params$max_range`.

```{r}
new_range <- assessment_pin %>%
  inner_join(assessment_data_small, by = "meta_pin") %>%
  mutate(!!params$added_feature := as.numeric(!!sym(params$added_feature))) %>%
  filter(!!sym(params$added_feature) > params$min_range &
    !!sym(params$added_feature) < params$max_range) %>%
  compute_stats(.)

comparison_range <- assessment_pin_comparison %>%
  inner_join(assessment_data_small, by = "meta_pin") %>%
  mutate(!!params$added_feature := as.numeric(!!sym(params$added_feature))) %>%
  filter(!!sym(params$added_feature) > params$min_range &
    !!sym(params$added_feature) < params$max_range) %>%
  compute_stats(.)

generate_comparison_table(new_range, comparison_range)
```


:::


# SHAP

The primary metric that the CCAO Data team uses to assess the importance of a feature is its SHAP value. SHAP values provide the amount of value each feature contributes to a parcel's predicted value. The SHAP value is calculated for each observation in the dataset, and the median SHAP value for a feature is used to determine the relative influence of that feature. The higher the median SHAP value, the more influential the feature is in the model.

## Absolute Value Rank of SHAP Scores


The following table produces the median absolute SHAP value by township, and creates a grouped table. In total, there are `r length(shap_predictors)` indicators in the model. Thus, if the median SHAP is ranked 1, it is the most important feature in a township, while if it is ranked `r length(shap_predictors)`, it is the least important feature in a township. The median value (without absolute) is also included to better contextualize the impact.


```{r shap_processing}
# Combine data
shap_df_filtered_long <- shap %>%
  inner_join(
    assessment_data %>%
      select(meta_pin, meta_card_num, meta_township_code, meta_nbhd_code) %>%
      rename(township_code = meta_township_code, neighborhood_code = meta_nbhd_code),
    by = c("meta_pin", "meta_card_num")
  ) %>%
  select(township_code, all_of(shap_predictors)) %>%
  pivot_longer(
    cols = all_of(shap_predictors),
    names_to = "feature",
    values_to = "shap"
  )

# Calculate median values for the overall data
overall_medians <- shap_df_filtered_long %>%
  group_by(feature) %>%
  summarize(
    median_abs_shap = median(abs(shap), na.rm = TRUE),
    median_shap = median(shap, na.rm = TRUE)
  ) %>%
  ungroup()

# Rank features based on median absolute SHAP values
ranked_overall_medians <- overall_medians %>%
  arrange(desc(median_abs_shap)) %>%
  mutate(rank_abs = row_number())

# Function to create summary tables
create_summary_table <- function(data, added_feature) {
  added_feature_data <- data %>%
    filter(feature == added_feature)

  if (nrow(added_feature_data) == 0) {
    return(NULL)
  }

  non_added_feature_data <- data %>%
    filter(feature != added_feature)

  combined_data <- bind_rows(added_feature_data, non_added_feature_data)

  kable_chart <- combined_data %>%
    select(feature, median_abs_shap, median_shap, rank_abs) %>%
    mutate(across(where(is.numeric), round, 2))

  datatable_chart <- datatable(kable_chart,
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )

  return(datatable_chart)
}

# Generate the overall summary table
added_feature <- params$added_feature
overall_summary_table <- create_summary_table(ranked_overall_medians, added_feature)

# Calculate median values for each township and rank features
ranked_shap_df <- shap_df_filtered_long %>%
  group_by(township_code, feature) %>%
  mutate(
    median_abs_shap = median(abs(shap), na.rm = TRUE),
    median_shap = median(shap, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  distinct(township_code, feature, .keep_all = TRUE) %>%
  group_by(township_code) %>%
  arrange(desc(median_abs_shap), .by_group = TRUE) %>%
  mutate(rank_abs = row_number()) %>%
  ungroup() %>%
  inner_join(ccao::town_dict, by = c("township_code" = "township_code"))

# Generate the township-specific tables
township_names <- unique(ranked_shap_df$township_name)
shap_tables <- lapply(township_names, function(name) {
  township_data <- ranked_shap_df %>%
    filter(township_name == name)
  create_summary_table(township_data, added_feature)
})
```


### Overall SHAP Summary
```{r shap_summary}
overall_summary_table
```


## SHAPS by Township
::: panel-tabset

### `r township_names[1]`


```{r, results = 'asis'}
shap_tables[[1]]
```
### `r township_names[2]`

```{r, results = 'asis'}
shap_tables[[2]]
```

### `r township_names[3]`


```{r, results = 'asis'}
shap_tables[[3]]
```

### `r township_names[4]`


```{r, results = 'asis'}
shap_tables[[4]]
```
### `r township_names[5]`


```{r, results = 'asis'}
shap_tables[[5]]
```

### `r township_names[6]`

```{r, results = 'asis'}
shap_tables[[6]]
```

###  `r township_names[7]`

```{r, results = 'asis'}
shap_tables[[7]]
```

###  `r township_names[8]`

```{r, results = 'asis'}
shap_tables[[8]]
```

###  `r township_names[9]`

```{r, results = 'asis'}
shap_tables[[9]]
```

###  `r township_names[10]`

```{r, results = 'asis'}
shap_tables[[10]]
```

###  `r township_names[11]`

```{r, results = 'asis'}
shap_tables[[11]]
```
###  `r township_names[12]`

```{r, results = 'asis'}
shap_tables[[12]]
```

###  `r township_names[13]`

```{r, results = 'asis'}
shap_tables[[13]]
```

###  `r township_names[14]`

```{r, results = 'asis'}
shap_tables[[14]]
```

###  `r township_names[15]`

```{r, results = 'asis'}
shap_tables[[15]]
```

###  `r township_names[16]`

```{r, results = 'asis'}
shap_tables[[16]]
```

###  `r township_names[17]`

```{r, results = 'asis'}
shap_tables[[17]]
```

###  `r township_names[18]`

```{r, results = 'asis'}
shap_tables[[18]]
```

###  `r township_names[19]`

```{r, results = 'asis'}
shap_tables[[19]]
```

###  `r township_names[20]`


```{r, results = 'asis'}
shap_tables[[20]]
```

###  `r township_names[21]`

```{r, results = 'asis'}
shap_tables[[21]]
```
###  `r township_names[22]`

```{r, results = 'asis'}
shap_tables[[22]]
```

###  `r township_names[23]`

```{r, results = 'asis'}
shap_tables[[23]]
```

###  `r township_names[24]`

```{r, results = 'asis'}
shap_tables[[24]]
```

###  `r township_names[25]`

```{r, results = 'asis'}
shap_tables[[25]]
```

###  `r township_names[26]`

```{r, results = 'asis'}
shap_tables[[26]]
```

###  `r township_names[27]`

```{r, results = 'asis'}
shap_tables[[27]]
```

###  `r township_names[28]`

```{r, results = 'asis'}
shap_tables[[28]]
```

###  `r township_names[29]`

```{r, results = 'asis'}
shap_tables[[29]]
```

###  `r township_names[30]`

```{r, results = 'asis'}
shap_tables[[30]]
```

###  `r township_names[31]`

```{r, results = 'asis'}
shap_tables[[31]]
```
###  `r township_names[32]`

```{r, results = 'asis'}
shap_tables[[32]]
```

###  `r township_names[33]`

```{r, results = 'asis'}
shap_tables[[33]]
```

###  `r township_names[34]`

```{r, results = 'asis'}
shap_tables[[34]]
```

###  `r township_names[35]`

```{r, results = 'asis'}
shap_tables[[35]]
```

###  `r township_names[36]`

```{r, results = 'asis'}
shap_tables[[36]]
```

###  `r township_names[37]`

```{r, results = 'asis'}
shap_tables[[37]]
```

###  `r township_names[38]`

```{r, results = 'asis'}
shap_tables[[38]]
```

:::

## SHAP Comparison

Here, we compare the SHAP values from the comparison data and the new data. The goal here is to see which other features, the added feature is influencing.
```{r shap_comparisons}
shap_comparison %>%
  inner_join(shap, by = c("meta_card_num", "meta_pin")) %>%
  select(-c(meta_pin, meta_card_num, meta_year.x, meta_year.y)) %>%
  rename_with(~ sub("\\.x$", "_comp", .), ends_with(".x")) %>%
  rename_with(~ sub("\\.y$", "_new", .), ends_with(".y")) %>%
  mutate(across(ends_with("_new"), ~ . - get(sub("_new$", "_comp", cur_column())), .names = "{sub('_new$', '_diff', .col)}")) %>%
  summarize(
    across(ends_with("_diff"), list(
      median_change = ~ median(.),
      median_abs_change = ~ median(abs(.))
    )),
    across(ends_with("_comp"), list(median_comp = ~ median(.))),
    across(ends_with("_new"), list(median_new = ~ median(.)))
  ) %>%
  pivot_longer(cols = everything(), names_to = c("feature", ".value"), names_sep = "_diff_|_comp_|_new_") %>%
  arrange(feature) %>%
  mutate(across(where(is.numeric), dollar, scale = 1, accuracy = 0.01)) %>%
  datatable(
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = FALSE,
      searching = TRUE
    ),
    rownames = FALSE
  )
```


## Correlation between SHAP and the Added Feature

```{r shap_feature_correlation}
correlation_value <- cor(pull(working_data_card, params$added_feature_shap), pull(working_data_card, params$added_feature), use = "complete.obs")
```

If the added feature leads to a significant change in predicted values, its correlation with the SHAP values should have a high absolute value. That correlation is `r round(correlation_value, 2)`.


```{r shap_feature_plot}
num_digits <- working_data_card %>%
  pull(!!sym(params$added_feature_shap)) %>%
  max(na.rm = TRUE) %>%
  floor() %>%
  as.character() %>%
  str_length()

if (params$type == "continuous") {
  working_data_card %>%
    select(meta_card_num, meta_pin, !!params$added_feature_shap, !!params$added_feature) %>%
    mutate(bin = cut_number(!!sym(params$added_feature), n = 10, dig.lab = num_digits)) %>%
    ggplot(aes(x = bin, y = !!sym(params$added_feature_shap))) +
    geom_boxplot(fill = "#69b3a2") +
    theme_minimal() +
    xlab("Feature Value") +
    ylab("SHAP Value") +
    scale_x_discrete(labels = function(x) {
      x <- gsub("\\.[^,\\]]*", "", x) # Remove everything between . and , or ]
      x <- gsub("[^0-9,,]", "", x) # Keep only numbers and ,
      gsub(",", "-", x)
    }) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
} else if (params$type == "categorical") {
  working_data_card %>%
    select(meta_card_num, meta_pin, !!params$added_feature_shap, !!params$added_feature) %>%
    mutate(feature_factor = factor(!!sym(params$added_feature))) %>%
    ggplot(aes(x = feature_factor, y = !!sym(params$added_feature_shap))) +
    geom_boxplot(fill = "#69b3a2") +
    theme_minimal() +
    xlab("Feature Value") +
    ylab("SHAP Value") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
}
```


# Spatial Analysis

The spatial analysis is broken up into a few sections. The first panel looks at four aggregated stats on the neighborhood level, the mean of the feature we are analyzing, the mean of the absolute value of the SHAP, the 90th percentile of the SHAP, and the change in FMV based on the added feature. 

## Neighborhood Values

::: panel-tabset

### Mean feature

```{r mean_feature}
if (params$type == "categorical") {
  spatial_data_pin %>%
    ggplot() +
    geom_sf(aes(fill = !!sym(paste0(params$added_feature, "_plurality_type")))) +
    scale_fill_viridis_d(option = "viridis", name = "Type of Plurality") +
    geom_sf(aes(alpha = !!sym(paste0(params$added_feature, "_plurality_percentage")))) +
    scale_alpha_continuous(name = "Percentage of Plurality") +
    theme_void() +
    coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
} else {
  spatial_data_pin %>%
    ggplot() +
    geom_sf(aes(fill = !!sym(paste0(params$added_feature, "_neighborhood_mean")))) +
    scale_fill_viridis_c(option = "viridis", name = "Value") +
    theme_void() +
    coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
}
```

### Mean Absolute SHAP

```{r mean_shap}
spatial_data_card %>%
  ggplot() +
  geom_sf(aes(fill = !!sym(paste0(params$added_feature_shap, "_neighborhood_mean")))) +
  scale_fill_viridis_c(option = "viridis", name = "Value") +
  theme_void() +
  coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
```

### 90th Percentile of Absolute SHAP

```{r 90th_percentile_shap}
spatial_data_card %>%
  ggplot() +
  geom_sf(aes(fill = !!sym(paste0(params$added_feature_shap, "_neighborhood_90th")))) +
  scale_fill_viridis_c(option = "viridis", name = "Value") +
  theme_void() +
  coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
```

### Median change in Neighborhood FMV
This value is defined as the neighborhood level median increase in value when adding the new feature to the model. For example, a value of 1% would mean that adding the feature increased properties within a neighborhood by 1%.

```{r neighborhood_change}
assessment_pin %>%
  select(meta_pin, loc_longitude, loc_latitude, pred_pin_final_fmv) %>%
  rename(pred_pin_final_fmv_new = pred_pin_final_fmv) %>%
  inner_join(assessment_pin_comparison, by = "meta_pin") %>%
  rename(pred_pin_final_fmv_comparison = pred_pin_final_fmv) %>%
  group_by(meta_nbhd_code) %>%
  summarize(
    median_fmv_new = median(pred_pin_final_fmv_new, na.rm = TRUE),
    median_fmv_comparison = median(pred_pin_final_fmv_comparison, na.rm = TRUE),
    fmv_ratio = (median_fmv_new / median_fmv_comparison) / median_fmv_comparison
  ) %>%
  inner_join(nbhd, by = c("meta_nbhd_code" = "town_nbhd")) %>%
  st_as_sf() %>%
  ggplot() +
  geom_sf(aes(fill = fmv_ratio)) +
  scale_fill_viridis_c(option = "viridis", name = "FMV Ratio", labels = scales::percent_format(accuracy = 0.001)) +
  theme_void() +
  coord_sf(xlim = c(-88.4, -87.52398), ylim = c(41.5, 42.2))
```

:::


```{r leaflet_function}
create_leaflet_map <- function(dataset, legend_value, legend_title, longitude = "loc_longitude", latitude = "loc_latitude") {
  # Convert the dataset to an sf object
  dataset_sf <- st_as_sf(dataset, coords = c(longitude, latitude), crs = 4326)

  # Filter neighborhoods that have at least one observation
  nbhd_borders <- nbhd %>%
    st_transform(crs = st_crs(dataset_sf)) %>%
    filter(st_intersects(., dataset_sf, sparse = FALSE) %>% rowSums() > 0)

  # Create the color palette
  pal <- colorNumeric(palette = "Reds", domain = dataset[[legend_value]])

  # Calculate the bounding box of the filtered neighborhoods
  bbox <- st_bbox(nbhd_borders)

  # Create the leaflet map
  leaflet(dataset) %>%
    addProviderTiles(providers$CartoDB.Positron) %>%
    addCircleMarkers(
      lng = ~ get(longitude),
      lat = ~ get(latitude),
      radius = 5,
      color = ~ pal(dataset[[legend_value]]),
      popup = ~ paste(
        "<br>", "Pin: ", dataset$meta_pin,
        "<br>", "SHAP:", dollar(dataset[[params$added_feature_shap]]),
        "<br>", "Relative SHAP", dataset$shap_relative,
        "<br>", "feature:", sprintf("%.2f", dataset[[params$added_feature]]),
        "<br>", "New FMV:", dataset$pred_pin_final_fmv_new,
        "<br>", "Comparison FMV: ", dataset$pred_pin_final_fmv_comparison,
        "<br>", "FMV Difference: ", dollar(dataset$diff_pred_pin_final_fmv)
      )
    ) %>%
    addPolygons(
      data = nbhd_borders,
      color = "black",
      weight = 2,
      fill = FALSE
    ) %>%
    addLegend(
      "bottomright",
      pal = pal,
      values = ~ dataset[[legend_value]],
      title = legend_title
    )
}
```

## Mapping the Highest and Lowest 100 Values
Three different types of high and low values are produced; the values of the feature we are analyzing, the impact that can be determined through the SHAPs, and the largest effects in change in FMV. Be careful interpreting values which are the max and min of the raw value, since ties are not accounted for. For example, if there are 10,000 parcels which are 0 feet from a newly constructed building, the map will not be a full representation. 

::: panel-tabset

### Largest 100 Values

```{r}
highest_100 <- working_data_pin %>%
  arrange(desc(!!sym(params$added_feature))) %>%
  slice(1:100)

create_leaflet_map(highest_100, params$added_feature, "Largest 100 Values")
```

### Lowest 100 Values

```{r}
lowest_100 <- working_data_pin %>%
  distinct(meta_pin, .keep_all = TRUE) %>%
  arrange(!!sym(params$added_feature)) %>%
  slice(1:100)

create_leaflet_map(lowest_100, params$added_feature, "Lowest 100 Values")
```

### Highest 100 SHAP Values

```{r}
highest_100 <- working_data_card %>%
  arrange(desc(!!sym(params$added_feature_shap))) %>%
  slice(1:100)

create_leaflet_map(highest_100, params$added_feature_shap, "Highest 100 SHAPs")
```

### Lowest 100 SHAP Values

```{r}
# Example usage with the dataset sliced outside the function
lowest_100 <- working_data_card %>%
  arrange(!!sym((params$added_feature_shap))) %>%
  slice(1:100)

create_leaflet_map(lowest_100, params$added_feature_shap, "Lowest 100 SHAPs")
```

### 100 Largest FMV Increases
```{r}
largest_fmv_increases <- working_data_pin %>%
  arrange(desc(diff_pred_pin_final_fmv)) %>%
  slice(1:100)

# Call the function with the pre-sliced dataset
create_leaflet_map(largest_fmv_increases, "diff_pred_pin_final_fmv", "Largest FMV Increases")
```

### 100 Largest FMV Decreases

```{r}
largest_fmv_decreases <- working_data_pin %>%
  arrange(diff_pred_pin_final_fmv) %>%
  slice(1:100)

create_leaflet_map(largest_fmv_decreases, "diff_pred_pin_final_fmv", "Largest FMV Decreases")
```

### 100 Largest FMV Initial Increases
```{r}
largest_fmv_increases <- working_data_card %>%
  arrange(desc(diff_pred_pin_initial_fmv)) %>%
  slice(1:100)

# Call the function with the pre-sliced dataset
create_leaflet_map(largest_fmv_increases, "diff_pred_pin_initial_fmv", "Largest FMV Increases")
```


### 100 Largest Initial FMV Decreases

```{r}
largest_fmv_decreases <- working_data_pin %>%
  arrange(diff_pred_pin_initial_fmv) %>%
  slice(1:100)

create_leaflet_map(largest_fmv_decreases, "diff_pred_pin_initial_fmv", "Largest FMV Decreases")
```
## Largest FMV Increase no Multicards

```{r}
largest_fmv_increases <- working_data_card %>%
  group_by(meta_pin) %>%
  filter(n() == 1) %>%
  ungroup() %>%
  arrange(desc(diff_pred_pin_final_fmv)) %>%
  slice(1:100)

create_leaflet_map(largest_fmv_increases, "diff_pred_pin_final_fmv", "Largest FMV Increases")
```

```{r}
largest_fmv_decreases <- working_data_card %>%
  group_by(meta_pin) %>%
  filter(n() == 1) %>%
  ungroup() %>%
  arrange(diff_pred_pin_initial_fmv) %>%
  slice(1:100)

create_leaflet_map(largest_fmv_increases, "diff_pred_pin_final_fmv", "Largest FMV Increases")
```



:::

## Neighborhoods with the Highest and Lowest SHAP Values

These maps identify neighborhoods where the added feature is having the largest impact on SHAP values. By selecting neighborhoods with the highest mean(absolute value), you can take a closer look at how individual parcels in these neighborhoods are affected.

::: panel-tabset
```{r processing_SHAP_values}
selected_data <- working_data_card %>%
  group_by(meta_nbhd_code) %>%
  mutate(mean_value = mean(abs(!!sym(paste0(params$added_feature_shap))), na.rm = TRUE)) %>%
  ungroup() %>%
  distinct(meta_nbhd_code, .keep_all = TRUE) %>%
  arrange(mean_value) %>%
  slice(c(1:2, (n() - 1):n())) %>%
  pull(meta_nbhd_code) %>%
  {
    filter(working_data_card, meta_nbhd_code %in% .)
  }

# Separate high and low mean value neighborhoods
high_mean_data <- selected_data %>%
  filter(meta_nbhd_code %in% selected_data$meta_nbhd_code[(length(selected_data$meta_nbhd_code) - 1):length(selected_data$meta_nbhd_code)])

low_mean_data <- selected_data %>%
  filter(meta_nbhd_code %in% selected_data$meta_nbhd_code[1:2])
```

### 2 Lowest SHAP Neighborhoods

```{r}
create_leaflet_map(low_mean_data, params$added_feature_shap, "SHAP Values")
```

### 2 Highest SHAP Neighborhoods

```{r}
create_leaflet_map(high_mean_data, params$added_feature_shap, "SHAP Values")
```

:::


## Within Neighborhood Largest Values

These maps display the top and bottom 10 SHAP values by parcel for each neighborhood. Because neighborhoods with *very* high FMVs have comparatively higher SHAP values, we also use a relative score, the percentage of a parcel's value determined by the new feature. This allows a comparison of within-neighborhood impact, while accounting for intra-neighborhood differences.

::: panel-tabset

### 10 Highest SHAP Values per Neighborhood

```{r}
top_10_data <- working_data_card %>%
  group_by(meta_nbhd_code) %>%
  top_n(10, wt = !!sym(paste0(params$added_feature_shap))) %>%
  ungroup()


create_leaflet_map(top_10_data, params$added_feature_shap, "SHAP Values")
```

### 10 Lowest SHAP values per neighborhood

```{r}
bottom_10_data <- working_data_card %>%
  group_by(meta_nbhd_code) %>%
  top_n(-10, wt = !!sym(paste0(params$added_feature_shap))) %>%
  ungroup()

create_leaflet_map(bottom_10_data, params$added_feature_shap, "SHAP Values")
```

### 10 Highest Relative SHAP values per neighborhood

```{r}
top_10_data_relative <- working_data_card %>%
  mutate(shap_relative_value = !!sym(params$added_feature_shap) / median_card_value) %>%
  group_by(meta_nbhd_code) %>%
  top_n(10, wt = shap_relative_value) %>%
  ungroup()


create_leaflet_map(top_10_data_relative, params$added_feature_shap, "Relative SHAP Values")
```
### Bottom 10 Relative SHAP Values per Neighborhood
```{r}
bottom_10_data_relative <- working_data_card %>%
  mutate(shap_relative_value = !!sym(params$added_feature_shap) / median_card_value) %>%
  group_by(meta_nbhd_code) %>%
  top_n(-10, wt = shap_relative_value) %>%
  ungroup()

create_leaflet_map(bottom_10_data_relative, params$added_feature_shap, "Relative SHAP Values")
```

:::

